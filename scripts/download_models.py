#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ AI –º–æ–¥–µ–ª–µ–π –¥–ª—è Jarvis AI Assistant
"""
import os
import sys
import subprocess
import asyncio
from pathlib import Path
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    required_packages = [
        'torch',
        'transformers',
        'openai-whisper',
        'TTS',
        'sentence-transformers'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
            logger.info(f"‚úì {package} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except ImportError:
            missing_packages.append(package)
            logger.warning(f"‚úó {package} –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    if missing_packages:
        logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–∞–∫–µ—Ç—ã: {', '.join(missing_packages)}")
        logger.info("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö –∫–æ–º–∞–Ω–¥–æ–π: pip install " + " ".join(missing_packages))
        return False
    
    return True

def download_whisper_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper"""
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper...")
    try:
        import whisper
        model = whisper.load_model("base")
        logger.info("‚úì Whisper –º–æ–¥–µ–ª—å 'base' –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥—Ä—É–≥–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
        sizes = ["tiny", "small", "medium", "large"]
        for size in sizes:
            try:
                whisper.load_model(size)
                logger.info(f"‚úì Whisper –º–æ–¥–µ–ª—å '{size}' –¥–æ—Å—Ç—É–ø–Ω–∞")
            except Exception as e:
                logger.warning(f"‚úó Whisper –º–æ–¥–µ–ª—å '{size}' –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
        
        return True
    except Exception as e:
        logger.error(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}")
        return False

def download_tts_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ TTS –º–æ–¥–µ–ª–∏"""
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ TTS –º–æ–¥–µ–ª–∏...")
    try:
        from TTS.api import TTS
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä—É—Å—Å–∫–æ–π –º–æ–¥–µ–ª–∏
        tts = TTS(model_name="tts_models/ru/ruslan")
        logger.info("‚úì TTS –º–æ–¥–µ–ª—å 'ruslan' –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä—É–≥–∏—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        available_models = TTS.list_models()
        russian_models = [model for model in available_models if 'ru' in model]
        
        logger.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ TTS –º–æ–¥–µ–ª–∏: {len(russian_models)}")
        for model in russian_models[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            logger.info(f"  - {model}")
        
        return True
    except Exception as e:
        logger.error(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ TTS: {e}")
        return False

def download_embedding_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    try:
        from sentence_transformers import SentenceTransformer
        
        model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        logger.info("‚úì –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ 'paraphrase-multilingual-MiniLM-L12-v2' –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
        test_texts = ["–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!", "Hello, world!"]
        embeddings = model.encode(test_texts)
        logger.info(f"‚úì –¢–µ—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ (—Ä–∞–∑–º–µ—Ä: {embeddings.shape})")
        
        return True
    except Exception as e:
        logger.error(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
        return False

def download_phi2_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Phi-2"""
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Phi-2...")
    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM
        
        model_name = "microsoft/phi-2"
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype="auto",
            trust_remote_code=True
        )
        
        logger.info("‚úì –ú–æ–¥–µ–ª—å Phi-2 –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
        test_prompt = "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"
        inputs = tokenizer(test_prompt, return_tensors="pt")
        with torch.no_grad():
            outputs = model.generate(**inputs, max_length=50, do_sample=True)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        logger.info(f"‚úì –¢–µ—Å—Ç Phi-2 –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ")
        
        return True
    except Exception as e:
        logger.error(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Phi-2: {e}")
        return False

def download_classification_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
    try:
        from transformers import pipeline
        
        classifier = pipeline(
            "text-classification",
            model="cointegrated/rubert-tiny2-cedr-emotion-detection"
        )
        
        logger.info("‚úì –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ 'rubert-tiny2' –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
        test_text = "–Ø –æ—á–µ–Ω—å —Ä–∞–¥!"
        result = classifier(test_text)
        logger.info(f"‚úì –¢–µ—Å—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ: {result}")
        
        return True
    except Exception as e:
        logger.error(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        return False

def create_model_info():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–æ–¥–µ–ª—è—Ö"""
    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª—è—Ö...")
    
    model_info = {
        "whisper": {
            "model": "base",
            "size": "~140MB",
            "languages": ["ru", "en", "es", "fr", "de", "it", "pt", "ja", "ko", "zh"],
            "description": "–ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ OpenAI Whisper"
        },
        "tts": {
            "model": "tts_models/ru/ruslan",
            "size": "~50MB",
            "languages": ["ru"],
            "description": "–ú–æ–¥–µ–ª—å —Å–∏–Ω—Ç–µ–∑–∞ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏"
        },
        "embedding": {
            "model": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "size": "~120MB",
            "languages": ["ru", "en", "es", "fr", "de", "it", "pt", "nl", "pl", "tr"],
            "description": "–ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
        },
        "phi2": {
            "model": "microsoft/phi-2",
            "size": "~2.7GB",
            "languages": ["en", "ru"],
            "description": "–ú–∞–ª–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å Microsoft Phi-2"
        },
        "classification": {
            "model": "cointegrated/rubert-tiny2-cedr-emotion-detection",
            "size": "~30MB",
            "languages": ["ru"],
            "description": "–ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —ç–º–æ—Ü–∏–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ"
        }
    }
    
    import json
    with open("shared/models/model_info.json", "w", encoding="utf-8") as f:
        json.dump(model_info, f, ensure_ascii=False, indent=2)
    
    logger.info("‚úì –§–∞–π–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª—è—Ö —Å–æ–∑–¥–∞–Ω")

def check_disk_space():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ"""
    import shutil
    
    total, used, free = shutil.disk_usage(".")
    free_gb = free // (1024**3)
    
    logger.info(f"–°–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ: {free_gb} GB")
    
    if free_gb < 5:
        logger.warning("‚ö†Ô∏è  –ú–∞–ª–æ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ (< 5GB)")
        logger.warning("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –º–µ—Å—Ç–æ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π")
        return False
    
    return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 50)
    print("  Jarvis AI Assistant - –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π")
    print("=" * 50)
    print()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    if not check_dependencies():
        logger.error("–ù–µ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        sys.exit(1)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
    if not check_disk_space():
        response = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É? (y/N): ")
        if response.lower() != 'y':
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
            sys.exit(0)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
    os.makedirs("shared/models", exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
    success_count = 0
    total_models = 5
    
    if download_whisper_model():
        success_count += 1
    
    if download_tts_model():
        success_count += 1
    
    if download_embedding_model():
        success_count += 1
    
    if download_phi2_model():
        success_count += 1
    
    if download_classification_model():
        success_count += 1
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª—è—Ö
    create_model_info()
    
    print()
    print("=" * 50)
    print(f"  –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {success_count}/{total_models} –º–æ–¥–µ–ª–µ–π")
    print("=" * 50)
    
    if success_count == total_models:
        logger.info("üéâ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        logger.info("Jarvis –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    else:
        logger.warning(f"‚ö†Ô∏è  –ó–∞–≥—Ä—É–∂–µ–Ω–æ {success_count} –∏–∑ {total_models} –º–æ–¥–µ–ª–µ–π")
        logger.warning("–ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
    
    print()
    print("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: shared/models/model_info.json")
    print("–ú–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")

if __name__ == "__main__":
    main()